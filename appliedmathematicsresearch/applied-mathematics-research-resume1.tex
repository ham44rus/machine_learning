\documentclass[aspectratio=169]{beamer}
\usepackage{amsmath, amssymb, bm}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{xcolor}

% Define \tr as trace operator
\newcommand{\tr}{\operatorname{tr}}

% 日本語環境設定: CJKutf8とzxjafontを併用し、より多くの日本語文字をサポート
\usepackage[ipaex]{zxjafont} % IPAexフォントを使用（IPAフォントの方が汎用的な場合もあります）
\usepackage{CJKutf8} % \begin{CJK}...\end{CJK} 環境のために残します

\usetheme{Madrid}
\usecolortheme{default}
\setbeamertemplate{navigation symbols}{}

\title{Wishart分布とその性質}
\subtitle{多変量正規分布の推定とBox-Cox変換}
\author{山北倫太郎}
\date{\today}

\begin{document}

% zxjafont を使用する場合、通常は\begin{CJK}...\end{CJK}環境は不要ですが、
% 互換性のために残す場合はコメントアウトを外してください。
% 今回は文字化けリスクを減らすため、コメントアウトしています。
% \begin{CJK}{UTF8}{min} 

\begin{frame}
\titlepage
\end{frame}

\begin{frame}{目次}
\tableofcontents
\end{frame}

\section{Wishart分布}

\begin{frame}{7.1 はじめに}
\begin{itemize}
    \item $X=\begin{pmatrix}x_1' \\ \vdots \\ x_n'\end{pmatrix}$ は標本行列を表す 。
    \item $\bar{x}$ と $S$ は、それぞれ $\mu$ と $\Sigma$ の一貫性のある不偏推定量を提供する 。
    \begin{itemize}
        \item $n\bar{x}=X'1$ (標本平均ベクトル($\bar{x}$))
        \item ここで、1は $n$ 次元のベクトルで、すべての要素が1である。\\
        \item $(n-1)S=X'X-n\bar{x}\bar{x}'$ (標本共分散行列(S))
        \item Sは母集団の共分散行列の不偏推定量であり、$X'X$ は標本行列の転置と自身の積である。
    \end{itemize}

\end{itemize}
\end{frame}
\begin{frame}{7.1 はじめに}
\begin{itemize}
    \item 7.2節では、$x_1, \dots, x_n$ が独立同分布で $x \sim N_p(\mu, \Sigma)$ かつ $\Sigma>0$ の場合の $\mu$ と $\Sigma$ の最尤推定量が導出される 。
    \item $\bar{x}$ と $S$ の同時分布に関する基本的な結果が命題7.1で証明される 。
    \item 7.3節では、Wishart分布の基本的な特性が研究される 。
    \item 7.4節では、データの多変量正規性を高めるためのBox-Cox変換が提示される 。
\end{itemize}
\end{frame}

\begin{frame}{7.2 $\bar{x}$ と $S$ の同時分布}
\begin{itemize}
    \item 正規性がある場合、$\bar{x}$ と $S$ はいくつかの点で「最適」である 。
    \item $V=(n-1)S$ とする 。
    \item $X$ の確率密度関数は様々な方法で記述できる 。
    \begin{equation*}
    f(X) = (2\pi)^{-np/2} |\Sigma|^{-n/2} \exp\left[-\frac{1}{2} \sum_{i=1}^{n} (x_i - \mu)' \Sigma^{-1} (x_i - \mu)\right] \tag{7.1}
    \end{equation*}
    \begin{equation*}
    = (2\pi)^{-np/2} |\Sigma|^{-n/2} e^{-\frac{n}{2}\mu'\Sigma^{-1}\mu} \text{etr}\left[-\frac{1}{2}\text{tr }\Sigma^{-1}X'X + n\mu'\Sigma^{-1}\bar{x}\right] 
    \end{equation*}
    \begin{equation*}
    = (2\pi)^{-np/2} |\Sigma|^{-n/2} \text{etr}\left[-\frac{1}{2}[V + n(\bar{x} - \mu)(\bar{x} - \mu)']\Sigma^{-1}\right] 
    \end{equation*}
\end{itemize}
\end{frame}

\begin{frame}{1行目}
確率変数ベクトル $X = (x_1, \dots, x_p)'$ が平均ベクトル $\mu$ と共分散行列 $\Sigma$ を持つ多変量正規分布に従う場合、その確率密度関数 $f(x)$ は次のように表される。
\begin{block}{p次元多変量正規分布の確率密度関数 (p.d.f.)}
\begin{equation*}
f(x) = (2\pi)^{-p/2} |\Sigma|^{-1/2} \exp\left(-\frac{1}{2}(x - \mu)'\Sigma^{-1}(x - \mu)\right)
\end{equation*}
\end{block}
\begin{itemize}
\item ここで、$x$ は確率変数ベクトル $X$ がとりうる値を示す $p$ 次元の列ベクトルである。
\item $\mu$ は、各確率変数の平均値を要素とする $p$ 次元の平均ベクトルである。
\item $\Sigma$ は、$p \times p$ の共分散行列であり、各確率変数間の分散と共分散を表す対称な正定値行列である。
\end{itemize}
\end{frame}

\begin{frame}{2行目}
exp[tr(⋅)]=etr(⋅)の記法を用いると、確率密度関数は次のように表される 。
\begin{align*}
&(x_i - \mu)'\Sigma^{-1}(x_i - \mu) \\
&= (x_i' - \mu')\Sigma^{-1}(x_i - \mu) \\
&= x_i'\Sigma^{-1}x_i - x_i'\Sigma^{-1}\mu - \mu'\Sigma^{-1}x_i + \mu'\Sigma^{-1}\mu \\
&= x_i'\Sigma^{-1}x_i - 2x_i'\Sigma^{-1}\mu + \mu'\Sigma^{-1}\mu \\
\end{align*}
\begin{itemize}
\item \text{ここで、}\(\mu'\Sigma^{-1}x_i\) はスカラー値であり、スカラーの転置は自分自身なので、\(\mu'\Sigma^{-1}x_i = (x_i'\Sigma^{-1}\mu)'\) です。\\
したがって、\(x_i'\Sigma^{-1}\mu\) と \(\mu'\Sigma^{-1}x_i\) は同じスカラー値を表します。
\end{itemize}
\end{frame}
\begin{frame}{2行目 (続き)} % フレームタイトルを修正して区別
exp[tr(⋅)]=etr(⋅)の記法を用いると、確率密度関数は次のように表される 。

\begin{align*}
&(x_i - \mu)'\Sigma^{-1}(x_i - \mu) \\
&= (x_i' - \mu')\Sigma^{-1}(x_i - \mu) \\
&= x_i'\Sigma^{-1}x_i - x_i'\Sigma^{-1}\mu - \mu'\Sigma^{-1}x_i + \mu'\Sigma^{-1}\mu \\
&= x_i'\Sigma^{-1}x_i - 2x_i'\Sigma^{-1}\mu + \mu'\Sigma^{-1}\mu \\
\end{align*}

ここで、$\mu'\Sigma^{-1}x_i$ はスカラー値であり、スカラーの転置は自分自身なので、$\mu'\Sigma^{-1}x_i = (x_i'\Sigma^{-1}\mu)'$ です。\\
したがって、$x_i'\Sigma^{-1}\mu$ と $\mu'\Sigma^{-1}x_i$ は同じスカラー値を表します。

\end{frame}

\begin{frame}{2行目 (さらに続き)} % フレームタイトルを修正して区別
\begin{itemize}
    \item $\mu'$は平均ベクトル$\mu$の転置を表し、$\mu$はp次元の列ベクトルなので、$\mu'$は1行p列の行ベクトルになります。
    \item $\Sigma^{-1}$は共分散行列$\Sigma$の逆行列を表し、$\Sigma$はp*pの正方行列なので、$\Sigma^{-1}$もp*pの正方行列になります。
    \item $x_i$はp次元の列ベクトルであり、$x_i'$はその転置で1行p列の行ベクトルになります。
\end{itemize}
よって、$(x_i - \mu)' \Sigma^{-1} (x_i - \mu)$はスカラー値であります。\\
また、$\mu'\Sigma^{-1}\mu\text{は、}e^{-\frac{1}{2}n\mu'\Sigma^{-1}\mu}$の形で指数関数に含まれます。
\end{frame}

\begin{frame}{1項目}
    \begin{itemize}
        \item 行列のトレースは、行列の対角成分の総和であり、$\text{tr}(A) = \sum_{i} a_{ii}$ で定義される。     \begin{block}{トレースの性質}
            \begin{itemize}
                \item $\text{tr}(AB) = \text{tr}(BA)$
                \item $\text{tr}(A) = \sum_{i=1}^{n} a_{ii}$, ここで $A = (a_{ij})$ は $n \times n$ 行列である。
            \end{itemize}
        \end{block}
    \end{itemize}
    \begin{align*}
    \sum_{i=1}^n x_i'\Sigma^{-1}x_i &= \sum_{i=1}^n \text{tr}\left(\Sigma^{-1} x_i x_i'\right) \\
    &= \text{tr}\left(\Sigma^{-1} \sum_{i=1}^n x_i x_i'\right) \\
    &= \text{tr}(\Sigma^{-1} X'X)
    \end{align*}
\end{frame}
\begin{frame}{1項目 (続き)} % フレームタイトルを修正して区別
    \begin{itemize}
        \item $X=\begin{pmatrix}x_1' \\ \vdots \\ x_n'\end{pmatrix}$ であるから、$X'X = \sum_{i=1}^n x_ix_i'$ となる。
        \item ここで、$x_i'$ は $x_i$ の転置を表し、$x_ix_i'$ は $x_i$ の外積を表す。
        \item $\Sigma^{-1}$ は共分散行列の逆行列であり、$x_ix_i'$ は $x_i$ の外積を表す。        
    \end{itemize}
\end{frame}
\begin{frame}{第2項目}
    \begin{align*}
    \sum_{i=1}^n -2x_i'\Sigma^{-1}\mu 
    &= -2(\sum_{i=1}^n x_i') \Sigma^{-1} \mu \\
    &= -2\left(\sum_{i=1}^n x_i'\right) \Sigma^{-1} \mu \\
    &\sum_{i=1}^n x_i' =  (x_1' + \cdots + x_n') = (n\bar{x})'\text{であるので} \\
    &= -2 (n\bar{x})' \Sigma^{-1} \mu \\
    &= -2 n\bar{x}' \Sigma^{-1} \mu \\
    \end{align*}
    %\begin{itemize}
     %   \item ここで、$\sum_{i=1}^n x_i' = (x_1' + \cdots + x_n') = n\bar{x}'$ である。
      %  \item $\text{tr}(AB) = \text{tr}(BA)$ の性質を利用している。
    %\end{itemize}
\end{frame}

\begin{frame}{第3項目}
\begin{align*}
\sum_{i=1}^n \mu'\Sigma^{-1}\mu\text{はスカラー値であり、これが n 回足されます。}\\
\sum_{i=1}^n \mu'\Sigma^{-1}\mu 
= n\mu'\Sigma^{-1}\mu
\end{align*}

したがって、これら3つの項を合わせると、指数部分は次のようになります。
\begin{align*}
\sum_{i=1}^n (x_i - \mu)'\Sigma^{-1}(x_i - \mu)
&= \sum_{i=1}^n x_i'\Sigma^{-1}x_i - 2n\bar{x}'\Sigma^{-1}\mu + n\mu'\Sigma^{-1}\mu \\
&= \mathrm{tr}(\Sigma^{-1} X'X) - 2n\bar{x}'\Sigma^{-1}\mu + n\mu'\Sigma^{-1}\mu
\end{align*}

\end{frame}

\begin{frame}{まとめると}
    \begin{align*}
    & -\frac{1}{2} \left[ \mathrm{tr}(\Sigma^{-1} X'X) - 2n\bar{x}'\Sigma^{-1}\mu + n\mu'\Sigma^{-1}\mu \right] \\
    &= -\frac{1}{2} \mathrm{tr}(\Sigma^{-1} X'X) + n\bar{x}'\Sigma^{-1}\mu - \frac{n}{2} \mu'\Sigma^{-1}\mu
    \end{align*}
    となり、2行目の指数部分と完全に一致します。
\end{frame}

\begin{frame}{3行目}
\begin{align*}
\sum_{i=1}^n (x_i - \mu)' \Sigma^{-1} (x_i - \mu)
&= \sum_{i=1}^n \left( (x_i - \bar{x}) + (\bar{x} - \mu) \right)' \Sigma^{-1} \left( (x_i - \bar{x}) + (\bar{x} - \mu) \right) \\
&= \sum_{i=1}^n (x_i - \bar{x})' \Sigma^{-1} (x_i - \bar{x}) + \sum_{i=1}^n (\bar{x} - \mu)' \Sigma^{-1} (\bar{x} - \mu) \\
&\quad + 2\sum_{i=1}^n (x_i - \bar{x})' \Sigma^{-1} (\bar{x} - \mu)\\
\end{align*}
\end{frame}

\begin{frame}{3行目 (続き)}
ここで、最後の項は
\[
2\left(\sum_{i=1}^n (x_i - \bar{x})\right)' \Sigma^{-1} (\bar{x} - \mu) = 2(n\bar{x} - n\bar{x})' \Sigma^{-1} (\bar{x} - \mu) = 0
\]
となるので、

\begin{align*}
\sum_{i=1}^n (x_i - \mu)' \Sigma^{-1} (x_i - \mu)
= \sum_{i=1}^n (x_i - \bar{x})' \Sigma^{-1} (x_i - \bar{x}) + n(\bar{x} - \mu)' \Sigma^{-1} (\bar{x} - \mu)\\
V = (n-1)S = \sum_{i=1}^n (x_i - \bar{x})(x_i - \bar{x})'
\end{align*}
\end{frame}

\begin{frame}{証明}
\begin{block}{証明}
\[
\begin{aligned}
\sum_{i=1}^n (x_i - \bar{x})(x_i - \bar{x})'
&= \sum_{i=1}^n \left[ x_i x_i' - x_i \bar{x}' - \bar{x} x_i' + \bar{x} \bar{x}' \right] \\
&= \sum_{i=1}^n x_i x_i' - \sum_{i=1}^n x_i \bar{x}' - \sum_{i=1}^n \bar{x} x_i' + \sum_{i=1}^n \bar{x} \bar{x}' \\
&= X'X - n\bar{x} \bar{x}' - n\bar{x} \bar{x}' + n\bar{x} \bar{x}' \\
&= X'X - n\bar{x} \bar{x}' \\
&= (n-1)S
\end{aligned}
\]
したがって、$\sum_{i=1}^n (x_i - \bar{x})(x_i - \bar{x})' = (n-1)S = V$ である。
\end{block}
\end{frame}

\begin{frame}{証明（各項の詳細な計算）}
\begin{itemize}
    \item $\sum_{i=1}^{n}\bm{x}_{i}\bm{x}_{i}^{\prime}$: 標本行列 $X$ は各行が $\bm{x}_{i}^{\prime}$（$\bm{x}_{i}$ は列ベクトル）として定義されるので、$X=\begin{pmatrix}\bm{x}_{1}^{\prime}\\ \bm{x}_{2}^{\prime}\\ \vdots\\ \bm{x}_{n}^{\prime}\end{pmatrix}$。その転置は $X^{\prime}=(\bm{x}_{1}\ \bm{x}_{2}\ \dots\ \bm{x}_{n})$ となる。したがって、$X^{\prime}X=\sum_{i=1}^{n}\bm{x}_{i}\bm{x}_{i}^{\prime}$。
    \item $\sum_{i=1}^{n}\bm{x}_{i}\overline{\bm{x}}^{\prime}$: $\overline{\bm{x}}^{\prime}$ は和のインデックス $i$ に依存しないので、$\sum_{i=1}^{n}\bm{x}_{i}\overline{\bm{x}}^{\prime} = (\sum_{i=1}^{n}\bm{x}_{i})\overline{\bm{x}}^{\prime} = n\overline{\bm{x}}\overline{\bm{x}}^{\prime}$。
    \item $\sum_{i=1}^{n}\overline{\bm{x}}\bm{x}_{i}^{\prime}$: $\overline{\bm{x}}$ も和のインデックス $i$ に依存しないので、$\sum_{i=1}^{n}\overline{\bm{x}}\bm{x}_{i}^{\prime} = \overline{\bm{x}}(\sum_{i=1}^{n}\bm{x}_{i}^{\prime}) = n\overline{\bm{x}}\overline{\bm{x}}^{\prime}$。
    \item $\sum_{i=1}^{n}\overline{\bm{x}}\overline{\bm{x}}^{\prime}$: これは $n$ 回足し合わせるので、$n\overline{\bm{x}}\overline{\bm{x}}^{\prime}$。
\end{itemize}
\end{frame}

\begin{frame}{7.2 $\bar{x}$ と $S$ の同時分布}
\begin{itemize}
    \item $(X'X, \bar{x})$ (または $(S, \bar{x})$ のような一対一関数) は、$(\Sigma, \mu)$ の最小十分完全統計量である 。
    \item Rao-Blackwell/Lehmann-Scheff\'eの定理により、不偏推定量の中で $(\bar{x}, S)$ は最小分散を持つ 。
    \item $n-1 \ge p$ の場合の最尤推定量 (MLE) $\hat{\mu}$ と $\hat{\Sigma}$ を得るには、対数尤度関数を最小化する 。
    \begin{equation*}
    \ln |\Sigma| + \text{tr }\frac{1}{n}V\Sigma^{-1} + (\bar{x} - \mu)'\Sigma^{-1}(\bar{x} - \mu) \tag{7.2}
    \end{equation*}
    \item 最尤推定量は $\hat{\mu} = \bar{x}$ と $\hat{\Sigma} = \frac{1}{n}V$ である 。
\end{itemize}
\end{frame}

\begin{frame}{Rao-Blackwellの定理とLehmann-Schefféの定理}
\begin{block}{定理 (Rao-Blackwell)}
$\hat{\theta}$ がパラメータ $\theta$ の不偏推定量であり、$T$ が十分統計量であるとする。このとき、$\hat{\theta}^* = E[\hat{\theta} \mid T]$ と定義すると、
\begin{itemize}
    \item $\hat{\theta}^*$ は $\theta$ の不偏推定量である。
    \item $\mathrm{Var}(\hat{\theta}^*) \leq \mathrm{Var}(\hat{\theta})$ が成り立つ。
\end{itemize}
\end{block}
\begin{block}{定理 (Lehmann-Scheffé)}
$T$ がパラメータ $\theta$ の完全かつ十分な統計量であるとする。もし $\hat{\theta}^* = g(T)$ が $T$ の関数であり、かつ $\theta$ の不偏推定量であるならば、$\hat{\theta}^*$ は $\theta$ の最小分散不偏推定量 (MVUE) である。
\end{block}
\end{frame}

\begin{frame}{なぜ $(X'X, \bar{x})$ または $(S, \bar{x})$ なのか？}
多変量正規分布の確率密度関数（尤度関数）の指数部分を見返すと、$\mu$ と $\Sigma$ を含む項が、$X'X$ と $\bar{x}$ の形で表現されていることがわかります。特に、
\[
\mathrm{etr}\left\{-\frac{1}{2}\left[V + n(\bar{x} - \mu)(\bar{x} - \mu)'\right]\Sigma^{-1}\right\}
\]
という形で書けることから、観測されたデータ $X$ の情報のうち、パラメータ $\mu$ と $\Sigma$ に影響を与える部分は、本質的に $V$（または $S$）と $\bar{x}$ に集約されていることが読み取れます。これにより、これらが十分統計量であることが示唆されます。
\end{frame}

\begin{frame}
\frametitle{前提となる事実}
\begin{itemize}
    \item $\bm{x}_i \sim N_p(\bm{\mu},\bm{\Sigma})$ (i.i.d.) 
    \item $\overline{\bm{x}} = \frac{1}{n}\sum_{i=1}^{n}\bm{x}_i$ 
    \item $(n-1)\bm{S}=\sum_{i=1}^{n}(\bm{x}_i-\overline{\bm{x}})(\bm{x}_i-\overline{\bm{x}})^{\prime}$ [これは $(n-1)\bm{S}=\bm{X}^{\prime}\bm{X}-n\overline{\bm{x}}\overline{\bm{x}}^{\prime}$ に等しい]
    \item $(\overline{\bm{x}},\bm{S})$ が $(\bm{\Sigma},\bm{\mu})$ に対して最小十分かつ完全な統計量である  。
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{ステップ1: 不偏性 (Unbiasedness) の確認}
\begin{block}{a. $\overline{\bm{x}}$ が $\bm{\mu}$ の不偏推定値であること}
\begin{align*}
E[\overline{\bm{x}}] &= E\left[\frac{1}{n}\sum_{i=1}^{n}\bm{x}_i\right] \\
&= \frac{1}{n}\sum_{i=1}^{n}E[\bm{x}_i]
\end{align*}
各 $\bm{x}_i$ は $N_p(\bm{\mu},\bm{\Sigma})$ に従うため、$E[\bm{x}_i]=\bm{\mu}$ です。
\begin{align*}
&= \frac{1}{n}\sum_{i=1}^{n}\bm{\mu} \\
&= \frac{1}{n}(n\bm{\mu}) \\
&= \bm{\mu}
\end{align*}
したがって、$E[\overline{\bm{x}}]=\bm{\mu}$ であり、$\overline{\bm{x}}$ は $\bm{\mu}$ の不偏推定値です。
\end{block}
\end{frame}

\begin{frame}
\frametitle{ステップ1: 不偏性 (Unbiasedness) の確認}
\begin{block}{b. $\bm{S}$ が $\bm{\Sigma}$ の不偏推定値であること}
\begin{align*}
E[\bm{S}] &= E\left[\frac{1}{n-1}\sum_{i=1}^{n}(\bm{x}_i-\overline{\bm{x}})(\bm{x}_i-\overline{\bm{x}})^{\prime}\right] \\
&= \frac{1}{n-1}E\left[\sum_{i=1}^{n}(\bm{x}_i\bm{x}_i^{\prime}-\bm{x}_i\overline{\bm{x}}^{\prime}-\overline{\bm{x}}\bm{x}_i^{\prime}+\overline{\bm{x}}\overline{\bm{x}}^{\prime})\right] \\
&= \frac{1}{n-1}\left(\sum_{i=1}^{n}E[\bm{x}_i\bm{x}_i^{\prime}]-\sum_{i=1}^{n}E[\bm{x}_i\overline{\bm{x}}^{\prime}]-\sum_{i=1}^{n}E[\overline{\bm{x}}\bm{x}_i^{\prime}]+\sum_{i=1}^{n}E[\overline{\bm{x}}\overline{\bm{x}}^{\prime}]\right)
\end{align*}
ここで、各項を評価します。
\begin{itemize}
    \item $E[\bm{x}_i\bm{x}_i^{\prime}]=\text{Cov}(\bm{x}_i)+E[\bm{x}_i]E[\bm{x}_i^{\prime}]=\bm{\Sigma}+\bm{\mu}\bm{\mu}^{\prime}$。
    \item $E[\overline{\bm{x}}\overline{\bm{x}}^{\prime}]=\text{Cov}(\overline{\bm{x}})+E[\overline{\bm{x}}]E[\overline{\bm{x}}^{\prime}]=\frac{1}{n}\bm{\Sigma}+\bm{\mu}\bm{\mu}^{\prime}$ (∵ $\overline{\bm{x}}\sim N_p(\bm{\mu},\frac{1}{n}\bm{\Sigma})$)。
    \item $\sum_{i=1}^{n}E[\bm{x}_i\overline{\bm{x}}^{\prime}]=E[(\sum_{i=1}^{n}\bm{x}_i)\overline{\bm{x}}^{\prime}]=E[n\overline{\bm{x}}\overline{\bm{x}}^{\prime}]=nE[\overline{\bm{x}}\overline{\bm{x}}^{\prime}]=n(\frac{1}{n}\bm{\Sigma}+\bm{\mu}\bm{\mu}^{\prime})=\bm{\Sigma}+n\bm{\mu}\bm{\mu}^{\prime}$。
    \item $\sum_{i=1}^{n}E[\overline{\bm{x}}\bm{x}_i^{\prime}]=E[\overline{\bm{x}}(\sum_{i=1}^{n}\bm{x}_i)^{\prime}]=E[\overline{\bm{x}}(n\overline{\bm{x}})^{\prime}]=nE[\overline{\bm{x}}\overline{\bm{x}}^{\prime}]=n(\frac{1}{n}\bm{\Sigma}+\bm{\mu}\bm{\mu}^{\prime})=\bm{\Sigma}+n\bm{\mu}\bm{\mu}^{\prime}$。
\end{itemize}
\end{block}
\end{frame}

\begin{frame}
\frametitle{ステップ1: 不偏性 (Unbiasedness) の確認 (続き)}
\begin{block}{b. $\bm{S}$ が $\bm{\Sigma}$ の不偏推定値であること (続き)}
これらを $E[\bm{S}]$ の式に代入します。
\begin{align*}
E[\bm{S}] &= \frac{1}{n-1}\left(\sum_{i=1}^{n}(\bm{\Sigma}+\bm{\mu}\bm{\mu}^{\prime})-(\bm{\Sigma}+n\bm{\mu}\bm{\mu}^{\prime})-(\bm{\Sigma}+n\bm{\mu}\bm{\mu}^{\prime})+n(\frac{1}{n}\bm{\Sigma}+\bm{\mu}\bm{\mu}^{\prime})\right) \\
&= \frac{1}{n-1}\left(n\bm{\Sigma}+n\bm{\mu}\bm{\mu}^{\prime}-\bm{\Sigma}-n\bm{\mu}\bm{\mu}^{\prime}-\bm{\Sigma}-n\bm{\mu}\bm{\mu}^{\prime}+\bm{\Sigma}+n\bm{\mu}\bm{\mu}^{\prime}\right) \\
&= \frac{1}{n-1}((n-1)\bm{\Sigma}) \\
&= \bm{\Sigma}
\end{align*}
したがって、$E[\bm{S}]=\bm{\Sigma}$ であり、$\bm{S}$ は $\bm{\Sigma}$ の不偏推定値です。
\end{block}
\end{frame}

\begin{frame}
\frametitle{ステップ2: Rao-Blackwell / Lehmann-Scheffé の定理の適用}
\begin{block}{Lehmann-Schefféの定理の記述}
Lehmann-Schefféの定理は、「もし、ある統計量 $T$ が完全かつ十分 (Complete and Sufficient) であり、$\hat{\bm{\theta}}^* = g(T)$ が $T$ の関数であり、かつパラメータ $\bm{\theta}$ の不偏推定値であるならば、$\hat{\bm{\theta}}^*$ は $\bm{\theta}$ の最小分散不偏推定量 (MVUE) である」と述べています。
\end{block}
\begin{block}{定理の適用}
\begin{itemize}
    \item パラメータ $\bm{\theta}$ は $(\bm{\mu},\bm{\Sigma})$ に対応します。
    \item 統計量 $T$ は $(\overline{\bm{x}},\bm{S})$ に対応します。テキストには、$(\bm{X}^{\prime}\bm{X},\overline{\bm{x}})$ (または $(\bm{S},\overline{\bm{x}})$ のような1対1関数) が $(\bm{\Sigma},\bm{\mu})$ に対して最小十分かつ完全であることが述べられています  。
    \item $\overline{\bm{x}}$ は $T=(\overline{\bm{x}},\bm{S})$ の関数（具体的には第一成分）であり、ステップ1で $\bm{\mu}$ の不偏推定値であることを示しました。
    \item $\bm{S}$ は $T=(\overline{\bm{x}},\bm{S})$ の関数（具体的には第二成分）であり、ステップ1で $\bm{\Sigma}$ の不偏推定値であることを示しました。
\end{itemize}
\end{block}
\end{frame}

\begin{frame}
\frametitle{結論}
\begin{block}{}
上記の条件がすべて満たされるため、Lehmann-Schefféの定理により、$\overline{\bm{x}}$ は $\bm{\mu}$ のMVUEであり、 $\bm{S}$ は $\bm{\Sigma}$ のMVUEであると結論付けられます。したがって、$(\overline{\bm{x}},\bm{S})$ は $(\bm{\Sigma},\bm{\mu})$ のMVUEであると述べることができます。
\end{block}
\end{frame}

\begin{frame}
\frametitle{最尤推定値 (MLE) の目的}
\begin{itemize}
    \item この式 $\text{ln}|\bm{\Sigma}|+\text{tr}\frac{1}{n}V\bm{\Sigma}^{-1}+(\overline{\bm{x}}-\bm{\mu})^{\prime}\bm{\Sigma}^{-1}(\overline{\bm{x}}-\bm{\mu})$ (7.2) を最小化するのは、未知のパラメータである平均ベクトル $\bm{\mu}$ と共分散行列 $\bm{\Sigma}$ の最尤推定値 (Maximum Likelihood Estimates, MLE) を求めるためです.
    \item 最尤推定法は、観測されたデータが最も「もっともらしい」と思われるようなパラメータの値を推定する統計的手法です.
    \item これを数学的に行うには、データの確率密度関数（または確率質量関数）をパラメータの関数と見なした「尤度関数」を最大化します.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{尤度関数から対数尤度関数へ}
\begin{itemize}
    \item 多変量正規分布の場合、観測された標本行列 $X$ の同時確率密度関数（尤度関数）は、以下のような形をしていました:
    \[
    f(X)=(2\pi)^{-\frac{np}{2}}|\bm{\Sigma}|^{-\frac{n}{2}}\text{etr}\left\{-\frac{1}{2}[V+n(\overline{\bm{x}}-\bm{\mu})(\overline{\bm{x}}-\bm{\mu})^{\prime}]\bm{\Sigma}^{-1}\right\} \quad \text{(7.1)} \text{}
    \]
    \item この尤度関数を直接最大化する代わりに、通常は計算が容易な対数尤度関数を最大化します.
    \item 上記の確率密度関数に自然対数 $\text{ln}$ を取ると、以下のようになります:
    \begin{align*}
    \text{ln}f(X)&=\text{ln}\left((2\pi)^{-\frac{np}{2}}|\bm{\Sigma}|^{-\frac{n}{2}}\text{etr}\left\{-\frac{1}{2}[V+n(\overline{\bm{x}}-\bm{\mu})(\overline{\bm{x}}-\bm{\mu})^{\prime}]\bm{\Sigma}^{-1}\right\}\right) \text{} \\
    &=-\frac{np}{2}\text{ln}(2\pi)-\frac{n}{2}\text{ln}|\bm{\Sigma}|-\frac{1}{2}\text{tr}\left([V+n(\overline{\bm{x}}-\bm{\mu})(\overline{\bm{x}}-\bm{\mu})^{\prime}]\bm{\Sigma}^{-1}\right) \text{}
    \end{align*}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{対数尤度関数の簡略化と最小化 (1)}
\begin{itemize}
    \item この対数尤度関数を $l(\bm{\Sigma},\bm{\mu})$ と表すとき、MLEを得るためには $l(\bm{\Sigma},\bm{\mu})$ を最大化する必要があります.
    \item ここで、定数項である $-\frac{np}{2}\text{ln}(2\pi)$ はパラメータ $\bm{\Sigma}$ や $\bm{\mu}$ に依存しないため、最大化には影響しません.
    \item したがって、最大化すべきは残りの項です:
    \[
    l(\bm{\Sigma},\bm{\mu})\propto-\frac{n}{2}\text{ln}|\bm{\Sigma}|-\frac{1}{2}\text{tr}\left([V+n(\overline{\bm{x}}-\bm{\mu})(\overline{\bm{x}}-\bm{\mu})^{\prime}]\bm{\Sigma}^{-1}\right)
    \]
    \item この式を最大化することは、符号を反転させて最小化することと同じです.
    \item そして、全体を $\frac{n}{2}$ で割っても最大化/最小化の結果は変わらないため、以下の式を最小化することになります:
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{対数尤度関数の簡略化と最小化 (2)}
\begin{align*}
&\frac{1}{n}\text{tr}\left([V+n(\overline{\bm{x}}-\bm{\mu})(\overline{\bm{x}}-\bm{\mu})^{\prime}]\bm{\Sigma}^{-1}\right)+\text{ln}|\bm{\Sigma}| \\
=&\frac{1}{n}\text{tr}(V\bm{\Sigma}^{-1})+\frac{1}{n}\text{tr}(n(\overline{\bm{x}}-\bm{\mu})(\overline{\bm{x}}-\bm{\mu})^{\prime}\bm{\Sigma}^{-1})+\text{ln}|\bm{\Sigma}| \\
=&\frac{1}{n}\text{tr}(V\bm{\Sigma}^{-1})+\text{tr}((\overline{\bm{x}}-\bm{\mu})(\overline{\bm{x}}-\bm{\mu})^{\prime}\bm{\Sigma}^{-1})+\text{ln}|\bm{\Sigma}| \\
=&\text{ln}|\bm{\Sigma}|+\text{tr}\frac{1}{n}V\bm{\Sigma}^{-1}+(\overline{\bm{x}}-\bm{\mu})^{\prime}\bm{\Sigma}^{-1}(\overline{\bm{x}}-\bm{\mu}) \quad \text{(7.2)}
\end{align*}
\begin{itemize}
    \item （最後の項はスカラーなので $\text{tr}$ を外すことができます。）
    \item この式は、テキストに示されている式 (7.2) と完全に一致します.
    \item したがって、この式を最小化する目的は、観測されたデータの下で、母集団パラメータである平均ベクトル $\bm{\mu}$ と共分散行列 $\bm{\Sigma}$ が最も「もっともらしい」値（すなわち最尤推定値）を見つけるためです.
\end{itemize}
\end{frame}

\begin{frame}[t]
\frametitle{ステップ1: $\hat{\bm{\mu}}=\overline{\bm{x}}$ の特定と最後の項の除去（まとめて解説）}
\small
\begin{itemize}
    \item テキストにあるように、「（最後の項は $\ge0$ なので）$\hat{\bm{\mu}}=\overline{\bm{x}}$ であることは明らか」です。
    \item この「最後の項」とは、$+(\overline{\bm{x}}-\bm{\mu})^{\prime}\bm{\Sigma}^{-1}(\overline{\bm{x}}-\bm{\mu})$ のことです。
    \item この項は、$\bm{\Sigma}$ が正定値行列（つまり $\bm{\Sigma}^{-1}$ も正定値行列）であるため、常に0以上（$\ge0$）です。
    \item この項を最小化するためには、その値を0にするのが最も小さい値です。
    \item $(\overline{\bm{x}}-\bm{\mu})^{\prime}\bm{\Sigma}^{-1}(\overline{\bm{x}}-\bm{\mu})=0$ となるのは、$\overline{\bm{x}}-\bm{\mu}=0$ のとき、すなわち $\bm{\mu}=\overline{\bm{x}}$ のときです。
    \item したがって、$\bm{\mu}$ に関する最尤推定値 $\hat{\bm{\mu}}$ は $\overline{\bm{x}}$ であると直ちに分かります。
    \item $\hat{\bm{\mu}}=\overline{\bm{x}}$ を元の式に代入すると、最後の項は0になります。
\end{itemize}
\begin{align*}
&\text{ln}|\bm{\Sigma}|+\text{tr}\frac{1}{n}V\bm{\Sigma}^{-1}+(\overline{\bm{x}}-\overline{\bm{x}})^{\prime}\bm{\Sigma}^{-1}(\overline{\bm{x}}-\overline{\bm{x}}) \\
=&\text{ln}|\bm{\Sigma}|+\text{tr}\frac{1}{n}V\bm{\Sigma}^{-1}+0^{\prime}\bm{\Sigma}^{-1}0 \\
=&\text{ln}|\bm{\Sigma}|+\text{tr}\frac{1}{n}V\bm{\Sigma}^{-1}
\end{align*}
\begin{itemize}
    \item これにより、$\bm{\Sigma}$ の最尤推定値 $\hat{\bm{\Sigma}}$ を得るためには、この簡略化された式を最小化すればよいことになります。
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{ステップ2: $\text{ln}|\bm{\Sigma}|$ の変形と $V$ の導入}
\begin{itemize}
    \item 最小化すべき式：
    \[ \text{ln}|\bm{\Sigma}|+\text{tr}\frac{1}{n}V\bm{\Sigma}^{-1} \]
    \item ここで、テキストでは「$\text{ln}|nV^{-1}\bm{\Sigma}|$」という項が導入されています。これは、最小化の問題をさらに簡潔にするための変数変換の準備です。
    \item 行列式の性質を利用します。
    \begin{itemize}
        \item $|AB|=|A||B|$
        \item $|cA|=c^p|A|$ （ここで $c$ はスカラー、$A$ は $p \times p$ 行列）
    \end{itemize}
    \item $\text{ln}|\bm{\Sigma}|$ を $V$ を含む形に変換するために、恒等式 $I=V^{-1}V$ を利用することを考えます。
    \begin{align*}
    \text{ln}|\bm{\Sigma}|&=\text{ln}|V^{-1}V\bm{\Sigma}| \\
    &=\text{ln}|V^{-1}(V\bm{\Sigma})| \\
    &=\text{ln}|nV^{-1}|+\text{ln}|\frac{1}{n}V\bm{\Sigma}|
    \end{align*}
\end{itemize}
\end{frame}
\begin{frame}
    \frametitle{式変形のまとめ (1)}
    \begin{itemize}
        \item 
        \[
        \text{ln}|nV^{-1}\bm{\Sigma}|+\text{tr}\frac{1}{n}V\bm{\Sigma}^{-1}
        \]
        \item これは、以下の恒等式（定数を追加・削除しても最小化の問題は変わらない）に基づいています。
        \[
        \text{ln}|\bm{\Sigma}| = \text{ln}|nV^{-1}\bm{\Sigma}| - \text{ln}|nV^{-1}|
        \]
        \item ここで、$\text{ln}|nV^{-1}|$ は $\bm{\Sigma}$ に依存しない定数です。
        \item したがって、最小化すべき式 $\text{ln}|\bm{\Sigma}|+\text{tr}\frac{1}{n}V\bm{\Sigma}^{-1}$ は、定数項 $\text{ln}|nV^{-1}|$ を追加（または削除）しても、$\bm{\Sigma}$ の最適値は変わりません。
    \end{itemize}
\end{frame}
\begin{frame}
    \frametitle{式変形のまとめ (2)}
    \begin{itemize}
        \item
        \begin{align*}
        &\text{ln}|\bm{\Sigma}|+\text{tr}\frac{1}{n}V\bm{\Sigma}^{-1} \\
        =&(\text{ln}|nV^{-1}\bm{\Sigma}|-\text{ln}|nV^{-1}|)+\text{tr}\frac{1}{n}V\bm{\Sigma}^{-1} \\
        =&\text{ln}|nV^{-1}\bm{\Sigma}|+\text{tr}\frac{1}{n}V\bm{\Sigma}^{-1}-\text{ln}|nV^{-1}|
        \end{align*}
        \item テキストでは、この定数項 $-\text{ln}|nV^{-1}|$ を「追加された定数」として無視し、以下の式を最小化することに焦点を当てています。
        \[
        \text{ln}|nV^{-1}\bm{\Sigma}|+\text{tr}\frac{1}{n}V\bm{\Sigma}^{-1}
        \]
    \end{itemize}
\end{frame}

\begin{frame}
\frametitle{ステップ3: $\bm{\Sigma}$ の MLE の最終導出}
定数 $\ln|nV^{-1}|$ は $\bm{\Sigma}$ の最適化には影響しません。条件 $n-1 \ge p$ は $V$ が確率1で非特異（正則）であることを保証します（これは後の系7.2で証明されます）。

変数変換 $T = nV^{-1}\bm{\Sigma}$ を導入すると、最小化すべき式は
\[
\ln|T| + \mathrm{tr}(T^{-1})
\]
となります。この式は $T$ のすべての固有値が1のとき最小値をとります。したがって、$\hat{\bm{\Sigma}} = \frac{1}{n}V$ が最尤推定値となります。
\end{frame}

\begin{frame}
\frametitle{固有値による表現}
\begin{itemize}
    \item 対称行列 $T$ の場合、そのトレースと行列式は固有値 $\lambda_1,\lambda_2,\dots,\lambda_p$ を用いて次のように表現できます。
    \begin{itemize}
        \item $\tr(T)=\sum_{j=1}^{p}\lambda_j$
        \item $|T|=\prod_{j=1}^{p}\lambda_j$
    \end{itemize}
    \item したがって、$\text{ln}|T|+\tr~T^{-1}$ は、固有値の関数として次のように書くことができます。
    \begin{itemize}
        \item $\text{ln}|T|=\text{ln}(\prod_{j=1}^{p}\lambda_j)=\sum_{j=1}^{p}\text{ln}(\lambda_j)$
        \item $\tr(T^{-1})=\sum_{j=1}^{p}\frac{1}{\lambda_j}$ （$T$ の固有値が $\lambda_j$ なら、$T^{-1}$ の固有値は $1/\lambda_j$）
    \end{itemize}
    \item これにより、最小化すべき関数は、各固有値 $\lambda_j$ の関数として次のように分解できます。
    \[ f(\lambda_1,\dots,\lambda_p)=\sum_{j=1}^{p}\left(\text{ln}(\lambda_j)+\frac{1}{\lambda_j}\right) \]
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{各固有値ごとの最小化 (1)}
\begin{itemize}
    \item この関数は、各固有値 $\lambda_j$ について独立に最小化できます。
    \[ g(\lambda)=\text{ln}(\lambda)+\frac{1}{\lambda} \]
    \item この関数 $g(\lambda)$ を最小化するために、$\lambda$ について微分し、導関数を0と置きます。
    \begin{align*}
        g^{\prime}(\lambda)&=\frac{d}{d\lambda}(\text{ln}(\lambda)+\lambda^{-1}) \\
        g^{\prime}(\lambda)&=\frac{1}{\lambda}-\frac{1}{\lambda^2}
    \end{align*}
    \item $g^{\prime}(\lambda)=0$ とすると、
    \begin{align*}
        \frac{1}{\lambda}-\frac{1}{\lambda^2}&=0 \\
        \frac{1}{\lambda}&=\frac{1}{\lambda^2} \\
        \lambda^2&=\lambda \\
        \lambda(\lambda-1)&=0
    \end{align*}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{各固有値ごとの最小化 (2)}
\begin{itemize}
    \item $\lambda=0$ または $\lambda=1$。
    \item しかし、行列式 $|T|$ は非ゼロでなければならない（ウィシャート分布の文脈で $V$ は非特異なので）ため、固有値 $\lambda$ は0ではありえません。
    \item したがって、唯一の極値点は $\lambda=1$ です。
    \item 二階微分を調べて、これが最小値であることを確認します。
    \begin{align*}
        g^{\prime\prime}(\lambda)&=\frac{d}{d\lambda}(\lambda^{-1}-\lambda^{-2}) \\
        g^{\prime\prime}(\lambda)&=-\lambda^{-2}+2\lambda^{-3}=-\frac{1}{\lambda^2}+\frac{2}{\lambda^3}
    \end{align*}
    \item $\lambda=1$ のとき、$g^{\prime\prime}(1)=-1+2=1>0$ なので、これは極小値であり、唯一の最小値です。
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{各固有値ごとの最小化 (3) および結論}
\begin{itemize}
    \item 関数 $f(\lambda_1,\dots,\lambda_p)$ は、すべての固有値 $\lambda_j$ が 1 のときに最小値を取ります。
    \item すべての固有値が1である対称行列は、単位行列 $I$ だけです。
    \item よって、$T = I$ のとき最小値となり、$nV^{-1}\hat{\bm{\Sigma}} = I$、すなわち $\hat{\bm{\Sigma}} = \frac{1}{n}V$ となります。
    \item これが多変量正規分布における共分散行列の最尤推定値です。
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{正規分布のMLE特性と場所族}
\begin{block}{備考}
Gaussに遡るよく知られた結果として、$\mathbb{R}$ 上の確率密度関数 $f(x-\theta)$ で、$x$ が $\theta$ の最尤推定量 (MLE) となる唯一の場所族は正規密度に由来します。\\
この正規密度のMLE特性は $\mathbb{R}^p$ でも成り立ちます [Stadje (1993)]。\\
すなわち、$f(x-\theta)$ という形の密度で、$x$ が常に $\theta$ のMLEとなるのは正規分布の場合のみです。
\end{block}
\end{frame}

\begin{frame}{7.3 Wishart分布の性質 - 命題}
\begin{block}{命題 7.3}
$W \sim W_p(m)$ かつ $m \ge p$ ならば、$W$ は確率1で非特異である。
\end{block}

$W \overset{d}{=} Z'Z$ であり、$Z' = (z_1, \dots, z_m)$ かつ $z_i$ は独立同分布の $N_p(0, I)$ に従う。\\
$\text{rank } W \overset{d}{=} \text{rank } Z'Z = \text{rank } Z \ge \text{rank } (z_1, \dots, z_p)$ は確率1で $p$ となる。\\
したがって、$\text{rank } W$ は確率1で $p$ となる。
\end{frame}


\begin{frame}{7.2 $\bar{x}$ と $S$ の同時分布 (続き)}
\begin{itemize}
    \item 一般的な結果として、$\bar{x}$ は $N_p(\mu, \Sigma/n)$ に従う 。
    \item 標本行列 $X$ を $Z$ を用いて表す。$X \overset{d}{=} ZA' + 1\mu'$, ここで $Z \sim N_n^p(0, I_n \otimes I_p)$ かつ $\Sigma=AA'$ 。
    \item $\bar{x}$ と $S_x$ の分布は $\bar{x}$ と $S_z$ の分布に等しい 。
    \item $P=n^{-1}11'$ と $Q=I-n^{-1}11'$ は直交射影である 。
    \item $PZ \perp QZ$ であるため、$\bar{z} \perp S_z$ である 。
    \item $Q=HH'$ は直交基底を与えるため、$(n-1)S_z = Z'HH'Z = U'U$ となる 。
\end{itemize}
\end{frame}

\begin{frame}{7.2 $\bar{x}$ と $S$ の同時分布 (続き)}
\begin{block}{定義 7.1 Wishart分布}
$W \sim W_p(m)$ ならば $W \overset{d}{=} \sum_{i=1}^{m} z_i z_i'$, ここで $z_i$ は独立同分布で $N_p(0, I)$ に従う。\\
$V \sim W_p(m, \Sigma)$ ならば $V \overset{d}{=} AWA'$, ここで $\Sigma=AA'$ かつ $W \sim W_p(m)$。
\end{block}

\begin{block}{命題 7.1}
$x_i$ が独立同分布で $N_p(\mu, \Sigma)$ に従う場合 ($i=1, \dots, n$)、
\begin{itemize}
    \item $\bar{x} \sim N_p(\mu, \Sigma/n)$ 
    \item $(n-1)S \sim W_p(n-1, \Sigma)$ 
    \item $\bar{x} \perp S$ 
\end{itemize}
\end{block}
\end{frame}

\begin{frame}{7.3 Wishart分布の性質 - 補題}
\begin{block}{補題 7.1}
$Z = (z_{ij}) \in \mathbb{R}^{n \times n}$ が独立同分布の $N(0, 1)$ に従う場合、$P(|Z| = 0) = 0$。
\end{block}

$n=1$ の場合は $z_{11}$ が絶対連続分布を持つため、結果は成立する。\\
$Z$ を以下のように分割する。
\[
Z = \begin{pmatrix} z_{11} & z_{12}' \\ z_{21} & Z_{22} \end{pmatrix}
\]
$Z_{22} \in \mathbb{R}^{(n-1) \times (n-1)}$ に対して結果が成立すると仮定すると、
\[
P(|Z|=0) = P(|Z|=0, |Z_{22}| \ne 0) + P(|Z|=0, |Z_{22}|=0)
\]
\[
= P(z_{11} = z_{12}'Z_{22}^{-1}z_{21}, |Z_{22}| \ne 0)
\]
\[
= E[P(z_{11} = z_{12}'Z_{22}^{-1}z_{21}, |Z_{22}| \ne 0 | z_{12}, z_{21}, Z_{22})] = 0
\]
\end{frame}

\begin{frame}{7.3 Wishart分布の性質 - 系}
\begin{block}{系 7.1}
$Z = (z_{ij}) \in \mathbb{R}^{n \times n}$ が独立同分布の $N(0, 1)$ に従う場合、$P(|Z| = t) = 0, \forall t$。
\end{block}

$P(|Z| = t) = E[P(z_{11} = z_{12}'Z_{22}^{-1}z_{21} + t/|Z_{22}|, |Z_{22}| \ne 0 | z_{12}, z_{21}, Z_{22})] = 0$。\\
補題7.1と系7.1は、$Z$ が任意の絶対連続分布を持つ場合にも有効である。
\end{frame}

\begin{frame}{7.3 Wishart分布の性質 - 命題}
\begin{block}{命題 7.3}
$W \sim W_p(m)$ かつ $m \ge p$ ならば、$W$ は確率1で非特異である。
\end{block}

$W \overset{d}{=} Z'Z$ であり、$Z' = (z_1, \dots, z_m)$ かつ $z_i$ は独立同分布の $N_p(0, I)$ に従う。\\
$\text{rank } W \overset{d}{=} \text{rank } Z'Z = \text{rank } Z \ge \text{rank } (z_1, \dots, z_p)$ は確率1で $p$ となる。\\
したがって、$\text{rank } W$ は確率1で $p$ となる。
\end{frame}
% \end{CJK} % zxjafont を使用する場合、この環境は不要です。
\end{document}

